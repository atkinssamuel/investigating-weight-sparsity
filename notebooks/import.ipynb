{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "golden-platform",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "\n",
    "download_path = \"https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\"\n",
    "data = urllib.request.urlopen(download_path)\n",
    "\n",
    "text_chars = \"\"\n",
    "\n",
    "whitespace_replace_chars = [\"\\\\n\"]\n",
    "remove_chars = [\"'\", '\"', \"-\", \",\", \":\", \"?\", \"!\", \";\"]\n",
    "\n",
    "for line in data:\n",
    "    line = str(line).lower()[2:]\n",
    "    for replace_char in whitespace_replace_chars:\n",
    "        line = line.replace(replace_char, \" \")\n",
    "    for remove_char in remove_chars:\n",
    "        line = line.replace(remove_char, \"\")\n",
    "    text_chars += line\n",
    "text_chars = ' '.join(text_chars.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "heavy-twist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first citizen before we proceed any further hear me speak. all speak speak. first citizen you are all resolved rather to die than to famish all resolved. resolved. first citizen first you know caius marcius is chief enemy to the people. all we knowt we knowt. first citizen let us kill him and well have corn at our own price. ist a verdict all no more talking ont let it be done away away second citizen one word good citizens. first citizen we are accounted poor citizens the patricians good. what authority surfeits on would relieve us if they would yield us but the superfluity while it were wholesome we might guess they relieved us humanely but they think we are too dear the leanness that afflicts us the object of our misery is as an inventory to particularise their abundance our sufferance is a gain to them let us revenge this with our pikes ere we become rakes for the gods know i speak this in hunger for bread not in thirst for revenge. second citizen would you proceed especially against caius marcius all against him first hes a very dog to the commonalty. second citizen consider you what services he has done for his country first citizen very well and could be content to give him good report fort but that he pays himself with being proud. second citizen nay but speak not maliciously. first citizen i say unto you what he hath done famously he did it to that end though softconscienced men can be content to say it was for his country he did it to please his mother and to be partly proud which he is even till the altitude of his virtue. second citizen what he cannot help in his nature you account a vice in him. you must in no way say he is covetous. first citizen if i must not i need not be barren of accusations he hath faults with surplus to tire in repetition. what shouts are these the other side o the city is risen why stay we prating here to the capitol all come come. first citizen soft who comes here second citizen worthy menenius agrippa one that hath always love\n"
     ]
    }
   ],
   "source": [
    "print(text_chars[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "assured-integer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1061639\n"
     ]
    }
   ],
   "source": [
    "print(len(text_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "valid-prime",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def batches(data, batch_size=32):\n",
    "    l = len(data)\n",
    "    for i in range(0, l, batch_size):\n",
    "        yield data[i:min(i + batch_size, l)]\n",
    "\n",
    "def letter_to_index(letter):\n",
    "    return ALL_LETTERS.find(letter)\n",
    "\n",
    "def letter_to_tensor(letter):\n",
    "    letter_tensor = torch.zeros(1, N_LETTERS)\n",
    "    letter_tensor[0][letter_to_index(letter)] = 1\n",
    "    return letter_tensor\n",
    "\n",
    "def line_to_tensor(line):\n",
    "    line_tensor = torch.zeros(len(line), 1, N_LETTERS)\n",
    "    for i, letter in enumerate(line):\n",
    "        line_tensor[i][0][letter_to_index(letter)] = 1\n",
    "    return line_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "finished-belly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 57])\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "ALL_LETTERS = string.ascii_letters + \" .,;'\"\n",
    "N_LETTERS = len(ALL_LETTERS)\n",
    "\n",
    "print(line_to_tensor(text_chars[:10]).shape) # torch.Size([10, 1, 57]) = BATCH_SIZE x 1 x N_LETTERS\n",
    "\n",
    "data_lines = []\n",
    "for batch in batches(text_chars, batch_size=16):\n",
    "    data_lines.append(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "coordinated-lighting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 57])\n"
     ]
    }
   ],
   "source": [
    "print(line_to_tensor(data_lines[54]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "written-grounds",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import unicodedata\n",
    "\n",
    "def find_file_names(file_path_string):\n",
    "    return glob.glob(file_path_string)\n",
    "\n",
    "def to_ascii(string):\n",
    "    return \"\".join(char for char in unicodedata.normalize(\"NFD\", string)\n",
    "                  if unicodedata.category(char) != \"Mn\"\n",
    "                  and char in ALL_LETTERS)\n",
    "\n",
    "def read_lines(file):\n",
    "    data = open(file, encoding='utf-8').read().strip().split('\\n')\n",
    "    return [to_ascii(line) for line in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "short-picnic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../data/names_data/names/Scottish.txt', '../data/names_data/names/French.txt', '../data/names_data/names/Dutch.txt', '../data/names_data/names/Czech.txt', '../data/names_data/names/Irish.txt', '../data/names_data/names/Greek.txt', '../data/names_data/names/Italian.txt', '../data/names_data/names/Russian.txt', '../data/names_data/names/Japanese.txt', '../data/names_data/names/Arabic.txt', '../data/names_data/names/German.txt', '../data/names_data/names/Korean.txt', '../data/names_data/names/Polish.txt', '../data/names_data/names/Spanish.txt', '../data/names_data/names/Vietnamese.txt', '../data/names_data/names/Chinese.txt', '../data/names_data/names/Portuguese.txt', '../data/names_data/names/English.txt']\n"
     ]
    }
   ],
   "source": [
    "names_data_files = \"../data/names_data/names/*.txt\"\n",
    "\n",
    "print(find_file_names(names_data_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "boxed-answer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "data_dict = {}\n",
    "categories_list = []\n",
    "\n",
    "for file in find_file_names(names_data_files):\n",
    "    name_category = os.path.splitext(os.path.basename(file))[0]\n",
    "    categories_list.append(name_category)\n",
    "    lines = read_lines(file)\n",
    "    data_dict[name_category] = lines\n",
    "    \n",
    "N_CATEGORIES = len(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "signal-evaluation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Scottish', 'French', 'Dutch', 'Czech', 'Irish', 'Greek', 'Italian', 'Russian', 'Japanese', 'Arabic', 'German', 'Korean', 'Polish', 'Spanish', 'Vietnamese', 'Chinese', 'Portuguese', 'English'])\n",
      "['Smith', 'Brown', 'Wilson', 'Campbell', 'Stewart', 'Thomson', 'Robertson', 'Anderson', 'Macdonald', 'Scott']\n"
     ]
    }
   ],
   "source": [
    "print(data_dict.keys())\n",
    "print(data_dict[\"Scottish\"][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polished-socket",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
